{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/witold87/pub_haystack_unstructurized/blob/master/Retrieval_via_DPR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEH-CRbeA6NU"
      },
      "source": [
        "# Better Retrieval via \"Dense Passage Retrieval\"\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/witold87/pub_haystack_unstructurized/blob/master/Retrieval_via_DPR.ipynb)\n",
        "\n",
        "### Importance of Retrievers\n",
        "\n",
        "The Retriever has a huge impact on the performance of our overall search pipeline.\n",
        "\n",
        "\n",
        "### Different types of Retrievers\n",
        "#### Sparse\n",
        "Family of algorithms based on counting the occurrences of words (bag-of-words) resulting in very sparse vectors with length = vocab size.\n",
        "\n",
        "**Examples**: BM25, TF-IDF\n",
        "\n",
        "**Pros**: Simple, fast, well explainable\n",
        "\n",
        "**Cons**: Relies on exact keyword matches between query and text\n",
        " \n",
        "\n",
        "#### Dense\n",
        "These retrievers use neural network models to create \"dense\" embedding vectors. Within this family there are two different approaches: \n",
        "\n",
        "a) Single encoder: Use a **single model** to embed both query and passage.  \n",
        "b) Dual-encoder: Use **two models**, one to embed the query and one to embed the passage\n",
        "\n",
        "Recent work suggests that dual encoders work better, likely because they can deal better with the different nature of query and passage (length, style, syntax ...). \n",
        "\n",
        "**Examples**: REALM, DPR, Sentence-Transformers\n",
        "\n",
        "**Pros**: Captures semantinc similarity instead of \"word matches\" (e.g. synonyms, related topics ...)\n",
        "\n",
        "**Cons**: Computationally more heavy, initial training of model\n",
        "\n",
        "\n",
        "### \"Dense Passage Retrieval\"\n",
        "\n",
        "In this Tutorial, we want to highlight one \"Dense Dual-Encoder\" called Dense Passage Retriever. \n",
        "It was introdoced by Karpukhin et al. (2020, https://arxiv.org/abs/2004.04906. \n",
        "\n",
        "Original Abstract: \n",
        "\n",
        "_\"Open-domain question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as TF-IDF or BM25, are the de facto method. In this work, we show that retrieval can be practically implemented using dense representations alone, where embeddings are learned from a small number of questions and passages by a simple dual-encoder framework. When evaluated on a wide range of open-domain QA datasets, our dense retriever outperforms a strong Lucene-BM25 system largely by 9%-19% absolute in terms of top-20 passage retrieval accuracy, and helps our end-to-end QA system establish new state-of-the-art on multiple open-domain QA benchmarks.\"_\n",
        "\n",
        "Paper: https://arxiv.org/abs/2004.04906  \n",
        "Original Code: https://fburl.com/qa-dpr \n",
        "\n",
        "\n",
        "*Use this* [link](https://colab.research.google.com/github/deepset-ai/haystack/blob/master/tutorials/Tutorial6_Better_Retrieval_via_DPR.ipynb) *to open the notebook in Google Colab.*\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0fQnbW84mfI",
        "outputId": "0eda187f-bb51-4a19-aec5-0e5518924969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K27Y5FbA6NV"
      },
      "source": [
        "### Prepare environment\n",
        "\n",
        "#### Colab: Enable the GPU runtime\n",
        "Make sure you enable the GPU runtime to experience decent speed in this tutorial.  \n",
        "**Runtime -> Change Runtime type -> Hardware accelerator -> GPU**\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/deepset-ai/haystack/master/docs/_src/img/colab_gpu_runtime.jpg\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlZgP8q1A6NW",
        "outputId": "cf16d8db-4361-4f8b-898a-864f0f447c2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jan 17 07:12:47 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Make sure you have a GPU running\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NM36kbRFA6Nc",
        "outputId": "8ea3a9ca-d94a-47fe-de71-4309d081dc7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting grpcio-tools==1.34.1\n",
            "  Downloading grpcio_tools-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<4.0dev,>=3.5.0.post1 in /usr/local/lib/python3.7/dist-packages (from grpcio-tools==1.34.1) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.34.1 in /usr/local/lib/python3.7/dist-packages (from grpcio-tools==1.34.1) (1.43.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from grpcio-tools==1.34.1) (57.4.0)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.34.1->grpcio-tools==1.34.1) (1.15.0)\n",
            "Installing collected packages: grpcio-tools\n",
            "Successfully installed grpcio-tools-1.34.1\n",
            "Collecting git+https://github.com/deepset-ai/haystack.git\n",
            "  Cloning https://github.com/deepset-ai/haystack.git to /tmp/pip-req-build-1yu2xzju\n",
            "  Running command git clone -q https://github.com/deepset-ai/haystack.git /tmp/pip-req-build-1yu2xzju\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0) (57.4.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0) (0.37.1)\n",
            "Requirement already satisfied: torch<1.11,>1.9 in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0) (1.0.2)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.1 MB/s \n",
            "\u001b[?25hCollecting mlflow<=1.13.1\n",
            "  Downloading mlflow-1.13.1-py3-none-any.whl (14.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.1 MB 9.5 MB/s \n",
            "\u001b[?25hCollecting transformers==4.13.0\n",
            "  Downloading transformers-4.13.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 34.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0) (0.3.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0) (5.4.8)\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.72.0-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 793 kB/s \n",
            "\u001b[?25hCollecting uvicorn\n",
            "  Downloading uvicorn-0.17.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting gunicorn\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0) (1.1.5)\n",
            "Collecting elasticsearch<=7.10,>=7.7\n",
            "  Downloading elasticsearch-7.10.0-py2.py3-none-any.whl (321 kB)\n",
            "\u001b[K     |████████████████████████████████| 321 kB 47.8 MB/s \n",
            "\u001b[?25hCollecting elastic-apm\n",
            "  Downloading elastic_apm-6.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (359 kB)\n",
            "\u001b[K     |████████████████████████████████| 359 kB 50.0 MB/s \n",
            "\u001b[?25hCollecting tox\n",
            "  Downloading tox-3.24.5-py2.py3-none-any.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: coverage in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0) (3.7.1)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 49.6 MB/s \n",
            "\u001b[?25hCollecting pytesseract==0.3.7\n",
            "  Downloading pytesseract-0.3.7.tar.gz (13 kB)\n",
            "Collecting pillow==9.0.0\n",
            "  Downloading Pillow-9.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 35.6 MB/s \n",
            "\u001b[?25hCollecting pdf2image==1.14.0\n",
            "  Downloading pdf2image-1.14.0-py3-none-any.whl (10 kB)\n",
            "Collecting sentence-transformers>=0.4.0\n",
            "  Downloading sentence-transformers-2.1.0.tar.gz (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.8 MB/s \n",
            "\u001b[?25hCollecting python-multipart\n",
            "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 40.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0) (1.4.29)\n",
            "Collecting sqlalchemy_utils\n",
            "  Downloading SQLAlchemy_Utils-0.38.2-py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 7.7 MB/s \n",
            "\u001b[?25hCollecting faiss-cpu>=1.6.3\n",
            "  Downloading faiss_cpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 30.9 MB/s \n",
            "\u001b[?25hCollecting tika\n",
            "  Downloading tika-1.24.tar.gz (28 kB)\n",
            "Collecting httptools\n",
            "  Downloading httptools-0.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (402 kB)\n",
            "\u001b[K     |████████████████████████████████| 402 kB 47.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0) (3.2.5)\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0) (8.12.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from farm-haystack==1.0.0) (2.6.3)\n",
            "Collecting pymilvus\n",
            "  Downloading pymilvus-1.1.2-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting SPARQLWrapper\n",
            "  Downloading SPARQLWrapper-1.8.5-py3-none-any.whl (26 kB)\n",
            "Collecting mmh3\n",
            "  Downloading mmh3-3.0.0-cp37-cp37m-manylinux2010_x86_64.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting weaviate-client==2.5.0\n",
            "  Downloading weaviate_client-2.5.0-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting ray>=1.9.1\n",
            "  Downloading ray-1.9.2-cp37-cp37m-manylinux2014_x86_64.whl (57.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 57.6 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting dataclasses-json\n",
            "  Downloading dataclasses_json-0.5.6-py3-none-any.whl (25 kB)\n",
            "Collecting quantulum3\n",
            "  Downloading quantulum3-0.7.9-py3-none-any.whl (10.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.7 MB 34.3 MB/s \n",
            "\u001b[?25hCollecting azure-ai-formrecognizer==3.2.0b2\n",
            "  Downloading azure_ai_formrecognizer-3.2.0b2-py2.py3-none-any.whl (219 kB)\n",
            "\u001b[K     |████████████████████████████████| 219 kB 51.0 MB/s \n",
            "\u001b[?25hCollecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 39.1 MB/s \n",
            "\u001b[?25hCollecting uvloop==0.14\n",
            "  Downloading uvloop-0.14.0-cp37-cp37m-manylinux2010_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 40.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from azure-ai-formrecognizer==3.2.0b2->farm-haystack==1.0.0) (1.15.0)\n",
            "Collecting msrest>=0.6.21\n",
            "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting azure-core<2.0.0,>=1.13.0\n",
            "  Downloading azure_core-1.21.1-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[K     |████████████████████████████████| 178 kB 48.4 MB/s \n",
            "\u001b[?25hCollecting azure-common~=1.1\n",
            "  Downloading azure_common-1.1.27-py2.py3-none-any.whl (12 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0->farm-haystack==1.0.0) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 41.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0->farm-haystack==1.0.0) (21.3)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 49.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0->farm-haystack==1.0.0) (4.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0->farm-haystack==1.0.0) (3.4.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 44.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0->farm-haystack==1.0.0) (1.19.5)\n",
            "Collecting validators>=0.18.2\n",
            "  Downloading validators-0.18.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elasticsearch<=7.10,>=7.7->farm-haystack==1.0.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from elasticsearch<=7.10,>=7.7->farm-haystack==1.0.0) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.13.0->farm-haystack==1.0.0) (3.10.0.2)\n",
            "Collecting docker>=4.0.0\n",
            "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 49.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm-haystack==1.0.0) (1.1.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm-haystack==1.0.0) (0.3)\n",
            "Collecting databricks-cli>=0.8.7\n",
            "  Downloading databricks-cli-0.16.2.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm-haystack==1.0.0) (3.17.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm-haystack==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm-haystack==1.0.0) (1.3.0)\n",
            "Collecting azure-storage-blob>=12.0.0\n",
            "  Downloading azure_storage_blob-12.9.0-py2.py3-none-any.whl (356 kB)\n",
            "\u001b[K     |████████████████████████████████| 356 kB 47.0 MB/s \n",
            "\u001b[?25hCollecting prometheus-flask-exporter\n",
            "  Downloading prometheus_flask_exporter-0.18.7-py3-none-any.whl (17 kB)\n",
            "Collecting querystring-parser\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm-haystack==1.0.0) (0.4.2)\n",
            "Collecting gitpython>=2.1.0\n",
            "  Downloading GitPython-3.1.26-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 39.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm-haystack==1.0.0) (7.1.2)\n",
            "Collecting alembic<=1.4.1\n",
            "  Downloading alembic-1.4.1.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 35.5 MB/s \n",
            "\u001b[?25hCollecting Mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Collecting cryptography>=2.1.4\n",
            "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 39.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.1.4->azure-storage-blob>=12.0.0->mlflow<=1.13.1->farm-haystack==1.0.0) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.0.0->mlflow<=1.13.1->farm-haystack==1.0.0) (2.21)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow<=1.13.1->farm-haystack==1.0.0) (0.8.9)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.6.21->azure-ai-formrecognizer==3.2.0b2->farm-haystack==1.0.0) (1.3.0)\n",
            "Collecting isodate>=0.6.0\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 604 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.13.0->farm-haystack==1.0.0) (3.0.6)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray>=1.9.1->farm-haystack==1.0.0) (21.4.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray>=1.9.1->farm-haystack==1.0.0) (1.0.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray>=1.9.1->farm-haystack==1.0.0) (4.3.3)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-4.1.1-py3-none-any.whl (173 kB)\n",
            "\u001b[K     |████████████████████████████████| 173 kB 46.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray>=1.9.1->farm-haystack==1.0.0) (1.43.0)\n",
            "Collecting deprecated>=1.2.3\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray>=1.9.1->farm-haystack==1.0.0) (1.13.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.13.0->farm-haystack==1.0.0) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->farm-haystack==1.0.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->farm-haystack==1.0.0) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-formrecognizer==3.2.0b2->farm-haystack==1.0.0) (3.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->farm-haystack==1.0.0) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->farm-haystack==1.0.0) (1.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.4.0->farm-haystack==1.0.0) (0.11.1+cu111)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 46.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.4.2->farm-haystack==1.0.0) (1.1.2)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators>=0.18.2->weaviate-client==2.5.0->farm-haystack==1.0.0) (4.4.2)\n",
            "Collecting typing-inspect>=0.4.0\n",
            "  Downloading typing_inspect-0.7.1-py3-none-any.whl (8.4 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0\n",
            "  Downloading marshmallow-3.14.1-py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Collecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2\n",
            "  Downloading pydantic-1.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 31.9 MB/s \n",
            "\u001b[?25hCollecting starlette==0.17.1\n",
            "  Downloading starlette-0.17.1-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.6 MB/s \n",
            "\u001b[?25hCollecting anyio<4,>=3.0.0\n",
            "  Downloading anyio-3.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.8 MB/s \n",
            "\u001b[?25hCollecting sniffio>=1.1\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow<=1.13.1->farm-haystack==1.0.0) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow<=1.13.1->farm-haystack==1.0.0) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow<=1.13.1->farm-haystack==1.0.0) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask->mlflow<=1.13.1->farm-haystack==1.0.0) (2.0.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray>=1.9.1->farm-haystack==1.0.0) (5.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray>=1.9.1->farm-haystack==1.0.0) (0.18.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->farm-haystack==1.0.0) (2018.9)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow<=1.13.1->farm-haystack==1.0.0) (0.12.0)\n",
            "Requirement already satisfied: grpcio-tools<1.38.0,>=1.22.0 in /usr/local/lib/python3.7/dist-packages (from pymilvus->farm-haystack==1.0.0) (1.34.1)\n",
            "Collecting ujson>=2.0.0\n",
            "  Downloading ujson-5.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting grpcio>=1.28.1\n",
            "  Downloading grpcio-1.37.1-cp37-cp37m-manylinux2014_x86_64.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 39.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from python-docx->farm-haystack==1.0.0) (4.2.6)\n",
            "Collecting num2words\n",
            "  Downloading num2words-0.5.10-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 11.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: inflect in /usr/local/lib/python3.7/dist-packages (from quantulum3->farm-haystack==1.0.0) (2.1.0)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words->quantulum3->farm-haystack==1.0.0) (0.6.2)\n",
            "Collecting rdflib>=4.0\n",
            "  Downloading rdflib-6.1.1-py3-none-any.whl (482 kB)\n",
            "\u001b[K     |████████████████████████████████| 482 kB 46.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: py>=1.4.17 in /usr/local/lib/python3.7/dist-packages (from tox->farm-haystack==1.0.0) (1.11.0)\n",
            "Collecting virtualenv!=20.0.0,!=20.0.1,!=20.0.2,!=20.0.3,!=20.0.4,!=20.0.5,!=20.0.6,!=20.0.7,>=16.0.0\n",
            "  Downloading virtualenv-20.13.0-py2.py3-none-any.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 41.7 MB/s \n",
            "\u001b[?25hCollecting pluggy>=0.12.0\n",
            "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: toml>=0.9.4 in /usr/local/lib/python3.7/dist-packages (from tox->farm-haystack==1.0.0) (0.10.2)\n",
            "Collecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.4.1-py3-none-any.whl (14 kB)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
            "\u001b[K     |████████████████████████████████| 461 kB 45.5 MB/s \n",
            "\u001b[?25hCollecting h11>=0.8\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting asgiref>=3.4.0\n",
            "  Downloading asgiref-3.4.1-py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: farm-haystack, pytesseract, alembic, databricks-cli, sentence-transformers, langdetect, python-docx, python-multipart, seqeval, tika\n",
            "  Building wheel for farm-haystack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for farm-haystack: filename=farm_haystack-1.0.0-py3-none-any.whl size=392702 sha256=b99b91ff80747cc7cc0fd83915cf4bbf1ccdb83572948027823a4ec0382a7ff2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_6f11f_s/wheels/a7/05/3b/9b33368d9af06a39f8e6af2e97fa2af876e893ade323cfc2c9\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.7-py2.py3-none-any.whl size=13954 sha256=4875669f4821bec52d83b4145a54d98247aa5e98909b17299769356c04d32ad1\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/71/6c/7a8c5ca2e699752506999ae7baeb692e2b4fc6488c2cddcb22\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158171 sha256=5504a5669361b248c72f5fcb153a56a81cce1bc1d401ec6b0ed35da89d3cfa00\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/5d/0a/9e13f53f4f5dfb67cd8d245bb7cdffe12f135846f491a283e3\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.16.2-py3-none-any.whl size=106811 sha256=e57b04b18583a7c45bff801bec8fecdb2ab20d3e5c6728d209cba56568b90dd2\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/5c/ed/e1ce20a53095f63b27b4964abbad03e59cf3472822addf7d29\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.1.0-py3-none-any.whl size=120999 sha256=2e76a369e3ebd23eecb648f559fa5487d45acba9d1dca28932c0a84a95a64e5d\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/f0/bb/ed1add84da70092ea526466eadc2bfb197c4bcb8d4fa5f7bad\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=b311f748f935e1c29ed1cd41ceb4c922dafdf14094ff02ff0f71623f33b158bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184507 sha256=7f8ca1ea35d8d3f53114b10f65ad41dbe666a3a34bd88bc16bb73d517146a317\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=220ad1d1b03b142eb32d7d0ca15c535fa46f1b1ae36f17c6922522f754c4b337\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/41/7c/bfd1c180534ffdcc0972f78c5758f89881602175d48a8bcd2c\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=e8a854056bd3e85e7201630f168ce40394efe62348292a71f10e60c36db3eba5\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-1.24-py3-none-any.whl size=32893 sha256=f2386f153bddf932e08300ec4a60c51939b95df30c3f41c2338bdcb0747f4087\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/2b/38/58ff05467a742e32f67f5d0de048fa046e764e2fbb25ac93f3\n",
            "Successfully built farm-haystack pytesseract alembic databricks-cli sentence-transformers langdetect python-docx python-multipart seqeval tika\n",
            "Installing collected packages: sniffio, smmap, pyyaml, isodate, websocket-client, tokenizers, sacremoses, python-editor, platformdirs, pillow, mypy-extensions, msrest, marshmallow, Mako, huggingface-hub, grpcio, gitdb, distlib, deprecated, cryptography, azure-core, anyio, virtualenv, validators, ujson, typing-inspect, transformers, starlette, sentencepiece, redis, rdflib, querystring-parser, pydantic, prometheus-flask-exporter, pluggy, num2words, marshmallow-enum, h11, gunicorn, gitpython, docker, databricks-cli, azure-storage-blob, azure-common, asgiref, alembic, weaviate-client, uvloop, uvicorn, tox, tika, sqlalchemy-utils, SPARQLWrapper, seqeval, sentence-transformers, ray, quantulum3, python-multipart, python-docx, pytesseract, pymilvus, psycopg2-binary, pdf2image, mmh3, mlflow, langdetect, httptools, fastapi, faiss-cpu, elasticsearch, elastic-apm, dataclasses-json, azure-ai-formrecognizer, farm-haystack\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.43.0\n",
            "    Uninstalling grpcio-1.43.0:\n",
            "      Successfully uninstalled grpcio-1.43.0\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pytest 3.6.4 requires pluggy<0.8,>=0.5, but you have pluggy 1.0.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Mako-1.1.6 SPARQLWrapper-1.8.5 alembic-1.4.1 anyio-3.5.0 asgiref-3.4.1 azure-ai-formrecognizer-3.2.0b2 azure-common-1.1.27 azure-core-1.21.1 azure-storage-blob-12.9.0 cryptography-36.0.1 databricks-cli-0.16.2 dataclasses-json-0.5.6 deprecated-1.2.13 distlib-0.3.4 docker-5.0.3 elastic-apm-6.7.2 elasticsearch-7.10.0 faiss-cpu-1.7.2 farm-haystack-1.0.0 fastapi-0.72.0 gitdb-4.0.9 gitpython-3.1.26 grpcio-1.37.1 gunicorn-20.1.0 h11-0.12.0 httptools-0.3.0 huggingface-hub-0.4.0 isodate-0.6.1 langdetect-1.0.9 marshmallow-3.14.1 marshmallow-enum-1.5.1 mlflow-1.13.1 mmh3-3.0.0 msrest-0.6.21 mypy-extensions-0.4.3 num2words-0.5.10 pdf2image-1.14.0 pillow-9.0.0 platformdirs-2.4.1 pluggy-1.0.0 prometheus-flask-exporter-0.18.7 psycopg2-binary-2.9.3 pydantic-1.9.0 pymilvus-1.1.2 pytesseract-0.3.7 python-docx-0.8.11 python-editor-1.0.4 python-multipart-0.0.5 pyyaml-6.0 quantulum3-0.7.9 querystring-parser-1.2.4 ray-1.9.2 rdflib-6.1.1 redis-4.1.1 sacremoses-0.0.47 sentence-transformers-2.1.0 sentencepiece-0.1.96 seqeval-1.2.2 smmap-5.0.0 sniffio-1.2.0 sqlalchemy-utils-0.38.2 starlette-0.17.1 tika-1.24 tokenizers-0.10.3 tox-3.24.5 transformers-4.13.0 typing-inspect-0.7.1 ujson-5.1.0 uvicorn-0.17.0 uvloop-0.14.0 validators-0.18.2 virtualenv-20.13.0 weaviate-client-2.5.0 websocket-client-1.2.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Install the latest release of Haystack in your own environment \n",
        "#! pip install farm-haystack\n",
        "\n",
        "# Install the latest master of Haystack\n",
        "!pip install grpcio-tools==1.34.1\n",
        "!pip install git+https://github.com/deepset-ai/haystack.git\n",
        "\n",
        "# If you run this notebook on Google Colab, you might need to\n",
        "# restart the runtime after installing haystack."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmRuhTQ7A6Nh"
      },
      "outputs": [],
      "source": [
        "from haystack.utils import clean_wiki_text, convert_files_to_dicts, fetch_archive_from_http, print_answers\n",
        "from haystack.nodes import FARMReader, TransformersReader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3dSo7ZtA6Nl"
      },
      "source": [
        "### Document Store\n",
        "\n",
        "#### Option 1: FAISS\n",
        "\n",
        "FAISS is a library for efficient similarity search on a cluster of dense vectors.\n",
        "The `FAISSDocumentStore` uses a SQL(SQLite in-memory be default) database under-the-hood\n",
        "to store the document text and other meta data. The vector embeddings of the text are\n",
        "indexed on a FAISS Index that later is queried for searching answers.\n",
        "The default flavour of FAISSDocumentStore is \"Flat\" but can also be set to \"HNSW\" for\n",
        "faster search at the expense of some accuracy. Just set the faiss_index_factor_str argument in the constructor.\n",
        "For more info on which suits your use case: https://github.com/facebookresearch/faiss/wiki/Guidelines-to-choose-an-index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cYgDJmrA6Nv",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from haystack.document_stores import FAISSDocumentStore\n",
        "\n",
        "document_store = FAISSDocumentStore(faiss_index_factory_str=\"Flat\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Y6dE5GDx3ndf"
      },
      "source": [
        "#### Option 2: Milvus\n",
        "\n",
        "Milvus is an open source database library that is also optimized for vector similarity searches like FAISS.\n",
        "Like FAISS it has both a \"Flat\" and \"HNSW\" mode but it outperforms FAISS when it comes to dynamic data management.\n",
        "It does require a little more setup, however, as it is run through Docker and requires the setup of some config files.\n",
        "See [their docs](https://milvus.io/docs/v1.0.0/milvus_docker-cpu.md) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "By3qBEMn3ndg",
        "outputId": "da007d2a-8dba-45ff-dc9b-6a73a0756866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING - haystack.utils.doc_store -  Automatic Milvus config creation not yet implemented. If you are starting Milvus using launch_milvus(), make sure you have a properly populated milvus/conf folder. See (https://milvus.io/docs/v1.0.0/milvus_docker-cpu.md) for more details.\n",
            "WARNING - haystack.utils.doc_store -  Tried to start Milvus through Docker but this failed. It is likely that there is already an existing Milvus instance running. \n",
            "Retry to connect server localhost:19530 failed.\n",
            "ERROR - milvus.client.grpc_handler -  Retry to connect server localhost:19530 failed.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotConnectError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFutureTimeoutError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/milvus/client/grpc_handler.py\u001b[0m in \u001b[0;36mping\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    210\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                     \u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/grpc/_utilities.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/grpc/_utilities.py\u001b[0m in \u001b[0;36m_block\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     85\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                             \u001b[0;32mraise\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFutureTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFutureTimeoutError\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotConnectError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c760a9d92adf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlaunch_milvus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdocument_store\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMilvusDocumentStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/haystack/document_stores/milvus.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sql_url, milvus_url, connection_pool, index, vector_dim, embedding_dim, index_file_size, similarity, index_type, index_param, search_param, return_embedding, embedding_field, progress_bar, duplicate_documents, isolation_level, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m         )\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmilvus_server\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMilvus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmilvus_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconnection_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvector_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/milvus/client/stub.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, host, port, handler, pool, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConnectionPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpool_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"SingletonThread\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingletonThreadPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpool_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Singleton\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleConnectionPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpool_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/milvus/client/pool.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, uri, pool_size, wait_timeout, try_connect, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;31m# if self._try_connect:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m#     self._max_retry = kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/milvus/client/pool.py\u001b[0m in \u001b[0;36m_prepare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_connect\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/milvus/client/grpc_handler.py\u001b[0m in \u001b[0;36mping\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFutureTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotConnectError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fail connecting to server on {}. Timeout'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotConnectError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Connect error: <{}>\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotConnectError\u001b[0m: Fail connecting to server on localhost:19530. Timeout"
          ]
        }
      ],
      "source": [
        "# from haystack.utils import launch_milvus\n",
        "# from haystack.document_stores import MilvusDocumentStore\n",
        "\n",
        "# launch_milvus()\n",
        "# document_store = MilvusDocumentStore()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "h8aNzpSA4IKv",
        "outputId": "23b5b8c7-1379-40c0-cbe6-6333fa229334",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading PyPDF2-1.26.0.tar.gz (77 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▎                           | 10 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20 kB 21.6 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 77 kB 3.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: PyPDF2\n",
            "  Building wheel for PyPDF2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyPDF2: filename=PyPDF2-1.26.0-py3-none-any.whl size=61102 sha256=999033440b08b37e71f766bf1e5dfd4f26dc913bec3c4354f420e40ce19f8ccb\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1a/24/648467ade3a77ed20f35cfd2badd32134e96dd25ca811e64b3\n",
            "Successfully built PyPDF2\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-1.26.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "folder = '/content/data/ar'\n",
        "for filename in os.listdir(folder):\n",
        "    file_path = os.path.join(folder, filename)\n",
        "    try:\n",
        "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "            os.unlink(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            shutil.rmtree(file_path)\n",
        "    except Exception as e:\n",
        "        print('Failed to delete %s. Reason: %s' % (file_path, e))"
      ],
      "metadata": {
        "id": "upgwnYCE-hfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "pdfFileObj = open('/content/drive/MyDrive/Colab Notebooks/Leave and License Agreement.pdf', 'rb')\n",
        "pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
        "number_pages=pdfReader.numPages\n",
        "print(\"Page count:\",number_pages)\n",
        "path=\"/content/data/ar/\"\n",
        "passages = []\n",
        "for i in range(number_pages):\n",
        "    try:\n",
        "        pageObj = pdfReader.getPage(i)\n",
        "        paragraph=pageObj.extractText()\n",
        "        doc_name=\"page_\"+str(i)+\"_\"+paragraph[:10]+\".txt\" \n",
        "        file1 = open(path+doc_name,\"w\")\n",
        "        file1.write(paragraph)\n",
        "        file1.close() \n",
        "        passages.append(paragraph)\n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "id": "Od61p2-u4Msw",
        "outputId": "74bc318a-0de9-4af8-a355-182c32aa11d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page count: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06LatTJBA6N0",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Cleaning & indexing documents\n",
        "\n",
        "Similarly to the previous tutorials, we download, convert and index some Game of Thrones articles to our DocumentStore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "b098e73973574581acda47436363ac3e",
            "ad4299f9e11f47009b9062524caf9c3a",
            "ac38470358ec4995a28275cba76c1f59",
            "ad7deb58c83948c1b47c2f4e9bc61dec",
            "94715338eaaf4685b3f1e520b712aed8",
            "18be60fc221846d9b1f17e3dd3a00e54",
            "f547ed3614494e04835c77d8c71a7dc2",
            "27482043fe3d4938ac587a50ee39f070",
            "658bb37346fa4279b89619467ea87b36",
            "7b1adb3af88145dd8553d9a227e344ac",
            "1533ba0fdd964f01bc7bd320db2860e5"
          ]
        },
        "id": "iqKnu6wxA6N1",
        "outputId": "5337e6f9-0d89-4ae5-bda0-c29a1912dc88",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - haystack.utils.import_utils -  Found data stored in `data/article_txt_got`. Delete this first if you really want to fetch new data.\n",
            "WARNING - haystack.document_stores.faiss -  DEPRECATION WARNINGS: \n",
            "                1. delete_all_documents() method is deprecated, please use delete_documents method\n",
            "                For more details, please refer to the issue: https://github.com/deepset-ai/haystack/issues/1045\n",
            "                \n",
            "INFO - haystack.utils.preprocessing -  Converting /content/data/ar/page_1_1.\n",
            " \n",
            "This .txt\n",
            "INFO - haystack.utils.preprocessing -  Converting /content/data/ar/page_0_ \n",
            " \n",
            "LEAVE .txt\n",
            "INFO - haystack.utils.preprocessing -  Converting /content/data/ar/page_2_premises o.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b098e73973574581acda47436363ac3e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Writing Documents:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Let's first get some files that we want to use\n",
        "doc_dir = \"data/article_txt_got\"\n",
        "s3_url = \"https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/documents/wiki_gameofthrones_txt.zip\"\n",
        "fetch_archive_from_http(url=s3_url, output_dir=doc_dir)\n",
        "doc_dir = \"/content/data/ar\"\n",
        "document_store.delete_all_documents()\n",
        "\n",
        "# Convert files to dicts\n",
        "dicts = convert_files_to_dicts(dir_path=doc_dir, clean_func=None, split_paragraphs=True)\n",
        "\n",
        "# Now, let's write the dicts containing documents to our DB.\n",
        "document_store.write_documents(dicts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgjedxx_A6N6"
      },
      "source": [
        "### Initalize Retriever, Reader & Pipeline\n",
        "\n",
        "#### Retriever\n",
        "\n",
        "**Here:** We use a `DensePassageRetriever`\n",
        "\n",
        "**Alternatives:**\n",
        "\n",
        "- The `ElasticsearchRetriever`with custom queries (e.g. boosting) and filters\n",
        "- Use `EmbeddingRetriever` to find candidate documents based on the similarity of embeddings (e.g. created via Sentence-BERT)\n",
        "- Use `TfidfRetriever` in combination with a SQL or InMemory Document store for simple prototyping and debugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347,
          "referenced_widgets": [
            "3c7c85b1c4644fcd830b1f7594117197",
            "0540b872da5e42a3b2dafaf934bde24c",
            "a95955249df94facb456c0ef40d5962a",
            "8e4e4bb93f0d486aa16f678a0780eb67",
            "809676b5719e4a71ac634266a2a83356",
            "13c1775b799e4892b2bbbbc4462e8a13",
            "af64bdaf787e4523a6fb3c968bd89909",
            "2d0fa7498ad44e20b0510768410cc049",
            "67a5bad885cb46f5b80008a84bb67937",
            "2009c38b62584802963edfbb39c6ebe7",
            "42d555bb4a8644fea8d122f71ec20b1a",
            "90335d2465514f6d91f88ff3cfa7e049",
            "c5ac6de027b84a65a39806f36bd38e2d",
            "76f63a5b548a477eb861928d4773aeb8",
            "bc285ce4640d4453a57af4074cd6d399",
            "49716ccf5e174e90a3d7e31c27abdb56",
            "69c489a70c2c40898430542cb674e0f9",
            "0282574dbd9345e1b290202f67eb605a",
            "b00a2ed8e39e4e13a1bc538a0d417162",
            "89bfd608296c4bf1ba9c219bb3e6c28c",
            "a40d547c1bcf46deb8c76e66b25202ad",
            "e598095d73e540478d1471cd6acaa4ab"
          ]
        },
        "id": "kFwiPP60A6N7",
        "outputId": "dba8a543-9b20-4d57-ddf1-6f78391d235c",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
            "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
            "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
            "INFO - haystack.modeling.model.language_model -  =============\n",
            "INFO - haystack.modeling.model.language_model -  Could not find facebook/dpr-question_encoder-single-nq-base locally.\n",
            "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
            "INFO - haystack.modeling.model.language_model -  Loaded facebook/dpr-question_encoder-single-nq-base\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
            "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
            "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
            "INFO - haystack.modeling.model.language_model -  =============\n",
            "INFO - haystack.modeling.model.language_model -  Could not find facebook/dpr-ctx_encoder-single-nq-base locally.\n",
            "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
            "INFO - haystack.modeling.model.language_model -  Loaded facebook/dpr-ctx_encoder-single-nq-base\n",
            "INFO - haystack.document_stores.faiss -  Updating embeddings for 5 docs...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c7c85b1c4644fcd830b1f7594117197",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Updating Embedding:   0%|          | 0/5 [00:00<?, ? docs/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90335d2465514f6d91f88ff3cfa7e049",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Create embeddings:   0%|          | 0/16 [00:00<?, ? Docs/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from haystack.nodes import DensePassageRetriever\n",
        "retriever = DensePassageRetriever(document_store=document_store,\n",
        "                                  query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
        "                                  passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
        "                                  max_seq_len_query=64,\n",
        "                                  max_seq_len_passage=256,\n",
        "                                  batch_size=16,\n",
        "                                  use_gpu=True,\n",
        "                                  embed_title=True,\n",
        "                                  use_fast_tokenizers=True)\n",
        "# Important: \n",
        "# Now that after we have the DPR initialized, we need to call update_embeddings() to iterate over all\n",
        "# previously indexed documents and update their embedding representation. \n",
        "# While this can be a time consuming operation (depending on corpus size), it only needs to be done once. \n",
        "# At query time, we only need to embed the query and compare it the existing doc embeddings which is very fast.\n",
        "document_store.update_embeddings(retriever)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnVR28OXA6OA"
      },
      "source": [
        "#### Reader\n",
        "\n",
        "Similar to previous Tutorials we now initalize our reader.\n",
        "\n",
        "Here we use a FARMReader with the *deepset/roberta-base-squad2* model (see: https://huggingface.co/deepset/roberta-base-squad2)\n",
        "\n",
        "\n",
        "\n",
        "##### FARMReader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyIuWVwhA6OB",
        "outputId": "9ba32106-eacc-4a1a-9215-900c05e64994"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - haystack.modeling.utils -  Using devices: CUDA\n",
            "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
            "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
            "INFO - haystack.modeling.model.language_model -  =============\n",
            "INFO - haystack.modeling.model.language_model -  Could not find deepset/roberta-base-squad2 locally.\n",
            "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
            "INFO - haystack.modeling.model.language_model -  Loaded deepset/roberta-base-squad2\n",
            "INFO - haystack.modeling.logger -  ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
            "INFO - haystack.modeling.utils -  Using devices: CUDA\n",
            "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
            "INFO - haystack.modeling.infer -  Got ya 2 parallel workers to do inference ...\n",
            "INFO - haystack.modeling.infer -   0    0 \n",
            "INFO - haystack.modeling.infer -  /w\\  /w\\\n",
            "INFO - haystack.modeling.infer -  /'\\  / \\\n"
          ]
        }
      ],
      "source": [
        "# Load a  local model or any of the QA models on\n",
        "# Hugging Face's model hub (https://huggingface.co/models)\n",
        "\n",
        "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unhLD18yA6OF"
      },
      "source": [
        "### Pipeline\n",
        "\n",
        "With a Haystack `Pipeline` you can stick together your building blocks to a search pipeline.\n",
        "Under the hood, `Pipelines` are Directed Acyclic Graphs (DAGs) that you can easily customize for your own use cases.\n",
        "To speed things up, Haystack also comes with a few predefined Pipelines. One of them is the `ExtractiveQAPipeline` that combines a retriever and a reader to answer our questions.\n",
        "You can learn more about `Pipelines` in the [docs](https://haystack.deepset.ai/docs/latest/pipelinesmd)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TssPQyzWA6OG"
      },
      "outputs": [],
      "source": [
        "from haystack.pipelines import ExtractiveQAPipeline\n",
        "pipe = ExtractiveQAPipeline(reader, retriever)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXlBBxKXA6OL"
      },
      "source": [
        "## Voilà! Ask a question!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi97Hif2A6OM",
        "outputId": "882d5b02-c636-4a47-fb2f-dbc6bcedbd0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). [prediction_head.py:462]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  5.78 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 18.70 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 21.10 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  9.48 Batches/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: How much is the deposit?\n",
            "Answers:\n",
            "[   {   'answer': 'Rs. \\n50000',\n",
            "        'context': 'permissive user as license only.\\n'\n",
            "                   ' \\n'\n",
            "                   ' \\n'\n",
            "                   '3.\\n'\n",
            "                   ' \\n'\n",
            "                   'T\\n'\n",
            "                   'he licensee shall deposit Rs. \\n'\n",
            "                   '50000\\n'\n",
            "                   ' \\n'\n",
            "                   'and keep deposited the said amount as \\n'\n",
            "                   'security deposit /m\\n'\n",
            "                   'oney adv'},\n",
            "    {   'answer': '1 \\nmonth/years',\n",
            "        'context': 'est or objection to the licensor on \\n'\n",
            "                   'expi\\n'\n",
            "                   'ry of the above period of \\n'\n",
            "                   '1 \\n'\n",
            "                   'month/years, from the date of executing this \\n'\n",
            "                   'present Agreement for Leav\\n'\n",
            "                   'e and'},\n",
            "    {   'answer': '5.\\n'\n",
            "                  ' \\n'\n",
            "                  'T\\n'\n",
            "                  'he licensee during the subsistence of this present '\n",
            "                  'agreement shall pay all \\n'\n",
            "                  'outgoing expenses,\\n'\n",
            "                  ' \\n'\n",
            "                  'and charges including for repairs, electricity and water \\n'\n",
            "                  'charges for electric and water consumption.\\n'\n",
            "                  '  \\n'\n",
            "                  ' \\n'\n",
            "                  '6.\\n'\n",
            "                  ' \\n'\n",
            "                  'The \\n'\n",
            "                  'licensee shall cease to use and occupy the licensed '\n",
            "                  'premises and hand \\n'\n",
            "                  'over licensed premises\\n'\n",
            "                  ' \\n'\n",
            "                  'without demur\\n'\n",
            "                  ',\\n'\n",
            "                  ' \\n'\n",
            "                  'protest or objection to the licensor on \\n'\n",
            "                  'expi\\n'\n",
            "                  'ry of the above period of \\n'\n",
            "                  '1 \\n'\n",
            "                  'month/years',\n",
            "        'context': '\\n'\n",
            "                   '5.\\n'\n",
            "                   ' \\n'\n",
            "                   'T\\n'\n",
            "                   'he licensee during the subsistence of this present '\n",
            "                   'agreement shall pay all \\n'\n",
            "                   'outgoing expenses,\\n'\n",
            "                   ' \\n'\n",
            "                   'and charges including for repairs, electricity and water \\n'\n",
            "                   'charges for electric and water consumption.\\n'\n",
            "                   '  \\n'\n",
            "                   ' \\n'\n",
            "                   '6.\\n'\n",
            "                   ' \\n'\n",
            "                   'The \\n'\n",
            "                   'licensee shall cease to use and occupy the licensed '\n",
            "                   'premises and hand \\n'\n",
            "                   'over licensed premises\\n'\n",
            "                   ' \\n'\n",
            "                   'without demur\\n'\n",
            "                   ',\\n'\n",
            "                   ' \\n'\n",
            "                   'protest or objection to the licensor on \\n'\n",
            "                   'expi\\n'\n",
            "                   'ry of the above period of \\n'\n",
            "                   '1 \\n'\n",
            "                   'month/year'},\n",
            "    {   'answer': 'Licensee',\n",
            "        'context': ' \\n     \\nLicensor\\n \\n \\n \\n \\n \\n \\nLicensee\\n '},\n",
            "    {   'answer': 'LEAVE AND LICENSE AGREEMENT\\n'\n",
            "                  ' \\n'\n",
            "                  ' \\n'\n",
            "                  '(To be executed while licencing premises) \\n'\n",
            "                  ' \\n'\n",
            "                  'This Agreement made at \\n'\n",
            "                  'Pune this 18\\n'\n",
            "                  ' \\n'\n",
            "                  'day of \\n'\n",
            "                  'Jan 2022\\n'\n",
            "                  ' \\n'\n",
            "                  'between \\n'\n",
            "                  'Ashitosh Shinde',\n",
            "        'context': ' \\n'\n",
            "                   'LEAVE AND LICENSE AGREEMENT\\n'\n",
            "                   ' \\n'\n",
            "                   ' \\n'\n",
            "                   '(To be executed while licencing premises) \\n'\n",
            "                   ' \\n'\n",
            "                   'This Agreement made at \\n'\n",
            "                   'Pune this 18\\n'\n",
            "                   ' \\n'\n",
            "                   'day of \\n'\n",
            "                   'Jan 2022\\n'\n",
            "                   ' \\n'\n",
            "                   'between \\n'\n",
            "                   'Ashitosh Shind'}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# You can configure how many candidates the reader and retriever shall return\n",
        "# The higher top_k for retriever, the better (but also the slower) your answers.\n",
        "prediction = pipe.run(\n",
        "    query=\"How much is the deposit?\", params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}}\n",
        ")\n",
        "print_answers(prediction, details=\"minimum\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXaat22_3ndn",
        "outputId": "19e17aee-80f8-4491-a561-7d6d7b8075e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: What are the key areas of business?\n",
            "Answers:\n",
            "[   {   'answer': 'Leave and License',\n",
            "        'context': 'shall be payable within first five days of the concerned \\n'\n",
            "                   'month of Leave and License. Licensees shall also pay to '\n",
            "                   'the Licensor Rs\\n'\n",
            "                   'the use of the said '},\n",
            "    {   'answer': 'month of Leave and License',\n",
            "        'context': 'es .\\n'\n",
            "                   'shall be payable within first five days of the concerned \\n'\n",
            "                   'month of Leave and License. Licensees shall also pay to '\n",
            "                   'the Licensor Rs\\n'\n",
            "                   'the use of the '},\n",
            "    {   'answer': 'named as also his respective heirs, successors, ass\\n'\n",
            "                  'igns, executors and administrators',\n",
            "        'context': 'reement is made and executed on \\n'\n",
            "                   'named as also his respective heirs, successors, ass\\n'\n",
            "                   'igns, executors and administrators)\\n'\n",
            "                   '_____________________________'},\n",
            "    {   'answer': 'the Licensee shall not claim any tenancy right and shall '\n",
            "                  'not have any right to\\n'\n",
            "                  'or any part thereof and also shall not mortgage or raise '\n",
            "                  'any loan against the said premises',\n",
            "        'context': 'the Licensee shall not claim any tenancy right and shall '\n",
            "                   'not have any right to\\n'\n",
            "                   'or any part thereof and also shall not mortgage or raise '\n",
            "                   'any loan against the said premises'},\n",
            "    {   'answer': 'AND BETWEEN THE PARTIES HERETO AS FOLLOWS:\\n'\n",
            "                  'That the Licensor hereby grants to the Licensee herein a '\n",
            "                  'revocable leave and license,\\n'\n",
            "                  'to occupy the Licensed Premises',\n",
            "        'context': '\\n'\n",
            "                   'AND BETWEEN THE PARTIES HERETO AS FOLLOWS:\\n'\n",
            "                   'That the Licensor hereby grants to the Licensee herein a '\n",
            "                   'revocable leave and license,\\n'\n",
            "                   'to occupy the Licensed Premise'}]\n"
          ]
        }
      ],
      "source": [
        "print_answers(prediction, details=\"minimum\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "yQ8l0oCn3ndn"
      },
      "source": [
        "## About us\n",
        "\n",
        "This [Haystack](https://github.com/deepset-ai/haystack/) notebook was made with love by [deepset](https://deepset.ai/) in Berlin, Germany\n",
        "\n",
        "We bring NLP to the industry via open source!  \n",
        "Our focus: Industry specific language models & large scale QA systems.  \n",
        "  \n",
        "Some of our other work: \n",
        "- [German BERT](https://deepset.ai/german-bert)\n",
        "- [GermanQuAD and GermanDPR](https://deepset.ai/germanquad)\n",
        "- [FARM](https://github.com/deepset-ai/FARM)\n",
        "\n",
        "Get in touch:\n",
        "[Twitter](https://twitter.com/deepset_ai) | [LinkedIn](https://www.linkedin.com/company/deepset-ai/) | [Slack](https://haystack.deepset.ai/community/join) | [GitHub Discussions](https://github.com/deepset-ai/haystack/discussions) | [Website](https://deepset.ai)\n",
        "\n",
        "By the way: [we're hiring!](https://www.deepset.ai/jobs)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Tutorial6_Better_Retrieval_via_DPR.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b098e73973574581acda47436363ac3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ad4299f9e11f47009b9062524caf9c3a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ac38470358ec4995a28275cba76c1f59",
              "IPY_MODEL_ad7deb58c83948c1b47c2f4e9bc61dec",
              "IPY_MODEL_94715338eaaf4685b3f1e520b712aed8"
            ]
          }
        },
        "ad4299f9e11f47009b9062524caf9c3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac38470358ec4995a28275cba76c1f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_18be60fc221846d9b1f17e3dd3a00e54",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Writing Documents: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f547ed3614494e04835c77d8c71a7dc2"
          }
        },
        "ad7deb58c83948c1b47c2f4e9bc61dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_27482043fe3d4938ac587a50ee39f070",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_658bb37346fa4279b89619467ea87b36"
          }
        },
        "94715338eaaf4685b3f1e520b712aed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7b1adb3af88145dd8553d9a227e344ac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10000/? [00:00&lt;00:00, 90236.18it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1533ba0fdd964f01bc7bd320db2860e5"
          }
        },
        "18be60fc221846d9b1f17e3dd3a00e54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f547ed3614494e04835c77d8c71a7dc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27482043fe3d4938ac587a50ee39f070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "658bb37346fa4279b89619467ea87b36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b1adb3af88145dd8553d9a227e344ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1533ba0fdd964f01bc7bd320db2860e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c7c85b1c4644fcd830b1f7594117197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0540b872da5e42a3b2dafaf934bde24c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a95955249df94facb456c0ef40d5962a",
              "IPY_MODEL_8e4e4bb93f0d486aa16f678a0780eb67",
              "IPY_MODEL_809676b5719e4a71ac634266a2a83356"
            ]
          }
        },
        "0540b872da5e42a3b2dafaf934bde24c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a95955249df94facb456c0ef40d5962a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_13c1775b799e4892b2bbbbc4462e8a13",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Documents Processed: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af64bdaf787e4523a6fb3c968bd89909"
          }
        },
        "8e4e4bb93f0d486aa16f678a0780eb67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2d0fa7498ad44e20b0510768410cc049",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67a5bad885cb46f5b80008a84bb67937"
          }
        },
        "809676b5719e4a71ac634266a2a83356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2009c38b62584802963edfbb39c6ebe7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10000/? [00:00&lt;00:00, 25976.91 docs/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42d555bb4a8644fea8d122f71ec20b1a"
          }
        },
        "13c1775b799e4892b2bbbbc4462e8a13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af64bdaf787e4523a6fb3c968bd89909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d0fa7498ad44e20b0510768410cc049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67a5bad885cb46f5b80008a84bb67937": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2009c38b62584802963edfbb39c6ebe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42d555bb4a8644fea8d122f71ec20b1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "90335d2465514f6d91f88ff3cfa7e049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c5ac6de027b84a65a39806f36bd38e2d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_76f63a5b548a477eb861928d4773aeb8",
              "IPY_MODEL_bc285ce4640d4453a57af4074cd6d399",
              "IPY_MODEL_49716ccf5e174e90a3d7e31c27abdb56"
            ]
          }
        },
        "c5ac6de027b84a65a39806f36bd38e2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76f63a5b548a477eb861928d4773aeb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_69c489a70c2c40898430542cb674e0f9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Create embeddings: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0282574dbd9345e1b290202f67eb605a"
          }
        },
        "bc285ce4640d4453a57af4074cd6d399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b00a2ed8e39e4e13a1bc538a0d417162",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 16,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 16,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_89bfd608296c4bf1ba9c219bb3e6c28c"
          }
        },
        "49716ccf5e174e90a3d7e31c27abdb56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a40d547c1bcf46deb8c76e66b25202ad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 16/16 [00:00&lt;00:00, 57.79 Docs/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e598095d73e540478d1471cd6acaa4ab"
          }
        },
        "69c489a70c2c40898430542cb674e0f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0282574dbd9345e1b290202f67eb605a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b00a2ed8e39e4e13a1bc538a0d417162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "89bfd608296c4bf1ba9c219bb3e6c28c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a40d547c1bcf46deb8c76e66b25202ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e598095d73e540478d1471cd6acaa4ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}